{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iw0jg7HkU1Sy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 144\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics # to evaluate classification accuracy\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array\n",
    "from tensorflow.keras.models import Model, load_model,Sequential\n",
    "from tensorflow.keras.layers import (Input, Dense, Dropout, Activation,\n",
    "                                     Flatten, BatchNormalization, Conv2D,\n",
    "                                     MaxPooling2D,GlobalAveragePooling2D)\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model,Sequential\n",
    "from tensorflow.keras.layers import (Input, Dense, Dropout, Activation,\n",
    "                                     Flatten, BatchNormalization, Conv2D,\n",
    "                                     MaxPooling2D,GlobalAveragePooling2D)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, models, layers, utils, activations, losses, optimizers, metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "#從路徑讀取圖像資料, 圖像資訊儲存成d_x,類別資訊儲存成d_y\n",
    "DATASET_PATH = r\"./jpg/\" #change\n",
    "# DATASET_PATH = r\"D:\\py\\YT\\AI2\\jpg\" + '\\\\' #change\n",
    "# DATASET_PATH = r\"D:\\py\\mid\\cnn\\training_set\\training_set\" +'//'\n",
    "\n",
    "d_x = []\n",
    "d_y = []\n",
    "\n",
    "df = pd.read_csv('./raw/data2.csv',dtype={'category':str}) #change\n",
    "# df = df.drop(['Context'], axis='columns')\n",
    "df= df.drop(columns=['Times'])\n",
    "df= df.drop(columns=['Impressions'])\n",
    "df= df.drop(columns=['ExposureCTR'])\n",
    "# df= df.drop(columns=['File_name'])\n",
    "df.columns\n",
    "\n",
    "nowpath = os.getcwd()\n",
    "try:   \n",
    "    shutil.rmtree('././.ipynb_checkpoints')\n",
    "#     print('clear   ././.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "df['category']=df['category'].astype(int)\n",
    "# for category in sorted(os.listdir(DATASET_PATH)):\n",
    "#     print('loading category: '+str(category))\n",
    "for fname in os.listdir(DATASET_PATH):\n",
    "    try:\n",
    "#             img = cv2.imread(DATASET_PATH, 1)\n",
    "        img = cv2.imread(DATASET_PATH+fname, 1)\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        d_x.append(np.reshape(img, [224,224,3]))\n",
    "        d_y.append(str(fname))\n",
    "    except:\n",
    "            pass\n",
    "print(len(d_x),len(d_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# os.listdir(DATASET_PATH+fname)\n",
    "# d_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_x = np.array(d_x).astype('float32') # 避免有些圖像像素太大, scale to 0-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lB_5YsAV77k.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5rnLJjhAn78.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0qJSTqfVEvE.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YW2RNQlMddw.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iYxgUD48QBg.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NCsOGXpAOs8.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>pfrUm2WB49s.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6omkNL68UEg.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>WbKoxonx9T4.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>qn_Ft8qTXtk.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           File_name  category\n",
       "0    lB_5YsAV77k.jpg         1\n",
       "1    5rnLJjhAn78.jpg         1\n",
       "2    0qJSTqfVEvE.jpg         1\n",
       "3    YW2RNQlMddw.jpg         1\n",
       "4    iYxgUD48QBg.jpg         1\n",
       "..               ...       ...\n",
       "139  NCsOGXpAOs8.jpg         0\n",
       "140  pfrUm2WB49s.jpg         0\n",
       "141  6omkNL68UEg.jpg         0\n",
       "142  WbKoxonx9T4.jpg         0\n",
       "143  qn_Ft8qTXtk.jpg         0\n",
       "\n",
       "[144 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "# d_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_y2=pd.DataFrame(d_y,columns=['File_name'])\n",
    "# # d_y3=pd.merge(d_y2,df, on='File_name')\n",
    "# d_y\n",
    "# d_y=d_y.copy()\n",
    "# d_y=d_y.drop(columns='File_name')\n",
    "# d_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9XVY7_EHYcjT"
   },
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# labelencoder = LabelEncoder()\n",
    "# d_y=pd.DataFrame(d_y)\n",
    "# d_y= labelencoder.fit_transform(d_y)\n",
    "# d_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "d_y=pd.DataFrame(d_y)\n",
    "d_y= labelencoder.fit_transform(d_y)\n",
    "d_y\n",
    "len(d_y)\n",
    "# y_data_list = pd.DataFrame(d_y, columns=['label'])\n",
    "# y_data = y_data_list['label']\n",
    "# d_y_onehot = tf.keras.utils.to_categorical(y_data, num_classes=2, dtype='float32')\n",
    "# print(d_y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = df[:int(len(df)*0.8)]\n",
    "# test = df[int(len(df)*0.8):]\n",
    "# train.shape, test.shape\n",
    "\n",
    "# \n",
    "\n",
    "train_x = d_x[:int(len(df)*0.8)]\n",
    "train_y = d_y[:int(len(df)*0.8)]\n",
    "vald_x = d_x[int(len(df)*0.8):]\n",
    "vald_y = d_y[int(len(df)*0.8):]\n",
    "\n",
    "# X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x = pd.get_dummies(train_x)\n",
    "# train_y = pd.get_dummies(train_y)\n",
    "# vald_x = pd.get_dummies(vald_x)\n",
    "# vald_y = pd.get_dummies(vald_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = train_x.shape[1],train_x.shape[2] \n",
    "input_shape = (img_rows, img_cols, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import legacy\n",
    "IMG_SIZE = 224\n",
    "tf.keras.backend.clear_session()\n",
    "base_model=tf.keras.applications.EfficientNetB0(include_top=False, # include classifiser ?\n",
    "                                                  weights='imagenet', \n",
    "                                                  input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base_model.output\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "model = models.Model(base_model.input, predictions)\n",
    "\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n",
    "optimizer = legacy.Adam(learning_rate=0.01, decay=1e-6)\n",
    "model.compile(optimizer = optimizer , \n",
    "              loss = \"binary_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'dropout')>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=10, \n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,  \n",
    "    horizontal_flip=True,  \n",
    "    vertical_flip=False,)  \n",
    "\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "# 定義 learning rate 根據 epoch 要如何變動\n",
    "def schedule(epoch):  \n",
    "    if epoch < 10:\n",
    "        return 0.0005\n",
    "    elif epoch < 30:\n",
    "        return 0.0003\n",
    "    elif epoch < 50:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.00005\n",
    "# 建立 LearningRateScheduler\n",
    "\n",
    "lr_schedule = callbacks.LearningRateScheduler(schedule, verbose=1)\n",
    "model_mckp = tf.keras.callbacks.ModelCheckpoint('Model/', # 模型輸出路徑\n",
    "                                             monitor='val_accuracy',\n",
    "                                             save_best_only=True,\n",
    "                                             verbose=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 1/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -1778.1777 - accuracy: 0.0000e+00\n",
      "Epoch 1: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 13s 877ms/step - loss: -1778.1777 - accuracy: 0.0000e+00 - val_loss: -4813.6401 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 2/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -5687.0972 - accuracy: 0.0174\n",
      "Epoch 2: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 13s 878ms/step - loss: -5687.0972 - accuracy: 0.0174 - val_loss: -16139.3037 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 3/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -11702.0400 - accuracy: 0.0087\n",
      "Epoch 3: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 13s 919ms/step - loss: -11702.0400 - accuracy: 0.0087 - val_loss: -25237.1602 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 4/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -16562.7852 - accuracy: 0.0087   \n",
      "Epoch 4: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 13s 904ms/step - loss: -16562.7852 - accuracy: 0.0087 - val_loss: -53719.6719 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 5/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -22765.5957 - accuracy: 0.0087\n",
      "Epoch 5: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 14s 960ms/step - loss: -22765.5957 - accuracy: 0.0087 - val_loss: -262005.8125 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 6/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -33306.3281 - accuracy: 0.0087\n",
      "Epoch 6: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 13s 890ms/step - loss: -33306.3281 - accuracy: 0.0087 - val_loss: -185818.8281 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 7/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -39362.0000 - accuracy: 0.0087\n",
      "Epoch 7: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 12s 845ms/step - loss: -39362.0000 - accuracy: 0.0087 - val_loss: -27938.4141 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 8/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -53732.3594 - accuracy: 0.0087\n",
      "Epoch 8: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 14s 996ms/step - loss: -53732.3594 - accuracy: 0.0087 - val_loss: -55642.9609 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 9/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -55711.8164 - accuracy: 0.0087\n",
      "Epoch 9: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 14s 941ms/step - loss: -55711.8164 - accuracy: 0.0087 - val_loss: -109897.6016 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 10/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -77471.1016 - accuracy: 0.0087\n",
      "Epoch 10: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 13s 875ms/step - loss: -77471.1016 - accuracy: 0.0087 - val_loss: -10000.0127 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0003.\n",
      "Epoch 11/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -99546.4844 - accuracy: 0.0087\n",
      "Epoch 11: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 13s 870ms/step - loss: -99546.4844 - accuracy: 0.0087 - val_loss: -70902.9062 - val_accuracy: 0.0000e+00 - lr: 3.0000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0003.\n",
      "Epoch 12/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -112754.0625 - accuracy: 0.0087\n",
      "Epoch 12: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 12s 864ms/step - loss: -112754.0625 - accuracy: 0.0087 - val_loss: -66207.5469 - val_accuracy: 0.0000e+00 - lr: 3.0000e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0003.\n",
      "Epoch 13/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -90426.0078 - accuracy: 0.0087 \n",
      "Epoch 13: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 13s 913ms/step - loss: -90426.0078 - accuracy: 0.0087 - val_loss: -113559.1562 - val_accuracy: 0.0000e+00 - lr: 3.0000e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0003.\n",
      "Epoch 14/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -97200.1094 - accuracy: 0.0087 \n",
      "Epoch 14: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 12s 860ms/step - loss: -97200.1094 - accuracy: 0.0087 - val_loss: -54602.9062 - val_accuracy: 0.0000e+00 - lr: 3.0000e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0003.\n",
      "Epoch 15/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -94052.5547 - accuracy: 0.0087  \n",
      "Epoch 15: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 12s 836ms/step - loss: -94052.5547 - accuracy: 0.0087 - val_loss: -53075.6719 - val_accuracy: 0.0000e+00 - lr: 3.0000e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0003.\n",
      "Epoch 16/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -114415.8750 - accuracy: 0.0087\n",
      "Epoch 16: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 13s 868ms/step - loss: -114415.8750 - accuracy: 0.0087 - val_loss: -9831.9141 - val_accuracy: 0.0000e+00 - lr: 3.0000e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0003.\n",
      "Epoch 17/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -103012.6641 - accuracy: 0.0087\n",
      "Epoch 17: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 13s 871ms/step - loss: -103012.6641 - accuracy: 0.0087 - val_loss: -1941.5380 - val_accuracy: 0.0000e+00 - lr: 3.0000e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0003.\n",
      "Epoch 18/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -110585.0078 - accuracy: 0.0087   \n",
      "Epoch 18: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 12s 862ms/step - loss: -110585.0078 - accuracy: 0.0087 - val_loss: -3857.2661 - val_accuracy: 0.0000e+00 - lr: 3.0000e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0003.\n",
      "Epoch 19/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -121518.1797 - accuracy: 0.0087\n",
      "Epoch 19: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 12s 853ms/step - loss: -121518.1797 - accuracy: 0.0087 - val_loss: -5406.5327 - val_accuracy: 0.0000e+00 - lr: 3.0000e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0003.\n",
      "Epoch 20/30\n",
      "15/14 [===============================] - ETA: 0s - loss: -144973.2500 - accuracy: 0.0087 \n",
      "Epoch 20: val_accuracy did not improve from 0.00000\n",
      "14/14 [==============================] - 12s 832ms/step - loss: -144973.2500 - accuracy: 0.0087 - val_loss: -114763.9141 - val_accuracy: 0.0000e+00 - lr: 3.0000e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0003.\n",
      "Epoch 21/30\n",
      "14/14 [============================>.] - ETA: 0s - loss: -163940.3906 - accuracy: 0.0093"
     ]
    }
   ],
   "source": [
    "#datagen.fit(train_x)\n",
    "\n",
    "history = model.fit(datagen.flow(train_x,train_y, \n",
    "                                 batch_size=8),\n",
    "                              steps_per_epoch=len(train_x) / 8, \n",
    "                              epochs=30,\n",
    "                              validation_data=(vald_x,vald_y),\n",
    "                              callbacks=[model_mckp,lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 224, 224, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 224, 244, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(115,224,244,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FM_SG.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
